{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289d5b78-6162-4bac-af94-b52d5c194158",
   "metadata": {},
   "source": [
    "# Requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "420984ea-3335-42a0-858e-0a1d4435e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch.func import functional_call, grad, vmap\n",
    "import torchopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d72e721-148e-4348-b11e-4fa7898c8c6a",
   "metadata": {},
   "source": [
    "# Differential equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef29346-dc44-4c53-9fe8-1bf5ce444010",
   "metadata": {},
   "source": [
    "The differential equation to solve is:\n",
    "$$\n",
    "    \\frac{d f}{dt} = R f(t)\\left(1 - f(t)\\right)\n",
    "$$\n",
    "with initial condition $f(0) = 0.5$.\n",
    "\n",
    "This equation can be used to model population growth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67e465-a82d-42b4-a832-bd80abbd5b94",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8454b80-e172-4bf8-aaeb-bd02b5957bbd",
   "metadata": {},
   "source": [
    "The loss function to train the neural network will be the sum of two terms, the first evaluates the differential equation in $M$ time points, the second enforces the initial conditions.\n",
    "$$\n",
    "    \\begin{array}{lcl}\n",
    "        L_{\\mathrm{DE}} & = & \\frac{1}{M} \\sum_{j=1}^{M} \\left( \\frac{df_{\\mathrm{NN}}}{dt}(t_j) - R f_{\\mathrm{NN}}(t_j) \\left( 1 - f_{\\mathrm{NN}}(t_j) \\right) \\right)^2 \\\\\n",
    "        L_{\\mathrm{BC}} & = & \\left( f_{\\mathrm{NN}}(0) - 0.5 \\right)^2 \\\\\n",
    "        L & = & L_{\\mathrm{DE}} + L_{\\mathrm{BC}}\n",
    "    \\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15acb49f-c285-4b57-be15-98d0f97556ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_to_dict_parameters(model, params):\n",
    "    keys = list(dict(model.named_parameters()).keys())\n",
    "    values = list(params)\n",
    "    return OrderedDict(({k:v for k, v in zip(keys, values)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40ec2dc8-457e-4eff-92f1-8dd5b726f21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_forward_fn(model, derivative_order=1):\n",
    "\n",
    "    def f(x: torch.Tensor, params: dict[str, torch.nn.Parameter] | tuple[torch.nn.Parameter, ...]) -> torch.Tensor:\n",
    "        if isinstance(params, tuple):\n",
    "            params_dict = tuple_to_dict_parameters(model, params)\n",
    "        else:\n",
    "            params_dict = params\n",
    "        return functional_call(model, params_dict, (x, ))\n",
    "\n",
    "    fns = [f]\n",
    "    dfunc = f\n",
    "    for _ in range(derivative_order):\n",
    "        dfunc = grad(dfunc)\n",
    "        fns.append(vmap(dfunc, in_dims=(0, None)))\n",
    "    return fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efecd1-85c3-4143-b4db-f89f71992ec3",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e234203f-9d86-4462-8670-aa7ba4d6953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, nr_inputs, nr_layers, nr_neurons, activation=torch.nn.Tanh()):\n",
    "        super().__init__()\n",
    "        self.num_inputs = nr_inputs\n",
    "        self.num_layers = nr_layers\n",
    "        self.num_neurons = nr_neurons\n",
    "        layers = []\n",
    "        layers.append(torch.nn.Linear(self.num_inputs, self.num_neurons))\n",
    "        for _ in range(self.num_layers):\n",
    "            layers.append(torch.nn.Linear(self.num_neurons, self.num_neurons))\n",
    "            layers.append(activation)\n",
    "        layers.append(torch.nn.Linear(self.num_neurons, 1))\n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x.reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f879a606-3b85-488b-a2f6-de3f45774f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PINN(nr_inputs=1, nr_neurons=20, nr_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0897090-7f4c-48c5-9e98-1a20ed846d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, dfdx = make_forward_fn(model, derivative_order=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08440717-e30d-4f97-bf77-39b03130acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "R, x_boundary, f_boundary = 1.0, 0.0, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cfe8788-5a39-4134-920f-fdc3d7b37d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(params, x):\n",
    "    f_value = f(x, params)\n",
    "    interior = dfdx(x, params) - R*f_value*(1.0 - f_value)\n",
    "    boundaries = f(torch.tensor([x_boundary]), params) - torch.tensor([f_boundary])\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return (loss(interior, torch.zeros_like(interior)) +\n",
    "            loss(boundaries, torch.zeros_like(boundaries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c661202-c375-4c75-9ae8-1018a90ced63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "nr_iters = 100\n",
    "learning_rate = 1.0e-1\n",
    "domain = (-5.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f62a320-d18d-4a7c-9673-cf0db5f4fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torchopt.FuncOptimizer(torchopt.adam(lr=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1846827-0111-4533-91f4-317245f10cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = tuple(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73d5134a-20ad-4247-b6a1-5180b3ee785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1 with loss 0.11463413387537003\n",
      "iteration 2 with loss 27.16790771484375\n",
      "iteration 3 with loss 0.6420497894287109\n",
      "iteration 4 with loss 2.8561654090881348\n",
      "iteration 5 with loss 3.5104665756225586\n",
      "iteration 6 with loss 2.035282611846924\n",
      "iteration 7 with loss 0.14833369851112366\n",
      "iteration 8 with loss 0.17722176015377045\n",
      "iteration 9 with loss 0.29466158151626587\n",
      "iteration 10 with loss 0.13089382648468018\n",
      "iteration 11 with loss 0.3749958872795105\n",
      "iteration 12 with loss 0.1261375993490219\n",
      "iteration 13 with loss 0.17460887134075165\n",
      "iteration 14 with loss 0.5559177994728088\n",
      "iteration 15 with loss 0.41323214769363403\n",
      "iteration 16 with loss 0.40801599621772766\n",
      "iteration 17 with loss 0.33771443367004395\n",
      "iteration 18 with loss 0.20494796335697174\n",
      "iteration 19 with loss 0.10330705344676971\n",
      "iteration 20 with loss 0.10414065420627594\n",
      "iteration 21 with loss 0.18002170324325562\n",
      "iteration 22 with loss 0.19086192548274994\n",
      "iteration 23 with loss 0.1662447154521942\n",
      "iteration 24 with loss 0.12068456411361694\n",
      "iteration 25 with loss 0.20130692422389984\n",
      "iteration 26 with loss 0.09801061451435089\n",
      "iteration 27 with loss 0.13131101429462433\n",
      "iteration 28 with loss 0.09928253293037415\n",
      "iteration 29 with loss 0.08115098625421524\n",
      "iteration 30 with loss 0.08818767964839935\n",
      "iteration 31 with loss 0.08493972569704056\n",
      "iteration 32 with loss 0.07110773026943207\n",
      "iteration 33 with loss 0.05105520784854889\n",
      "iteration 34 with loss 0.05446767061948776\n",
      "iteration 35 with loss 0.062104418873786926\n",
      "iteration 36 with loss 0.05202716961503029\n",
      "iteration 37 with loss 0.055305611342191696\n",
      "iteration 38 with loss 0.044861141592264175\n",
      "iteration 39 with loss 0.046682748943567276\n",
      "iteration 40 with loss 0.042420465499162674\n",
      "iteration 41 with loss 0.041048914194107056\n",
      "iteration 42 with loss 0.03341205418109894\n",
      "iteration 43 with loss 0.0331701822578907\n",
      "iteration 44 with loss 0.03715697303414345\n",
      "iteration 45 with loss 0.04585421085357666\n",
      "iteration 46 with loss 0.03548423945903778\n",
      "iteration 47 with loss 0.03360460698604584\n",
      "iteration 48 with loss 0.03336722403764725\n",
      "iteration 49 with loss 0.035427533090114594\n",
      "iteration 50 with loss 0.040354594588279724\n",
      "iteration 51 with loss 0.030506618320941925\n",
      "iteration 52 with loss 0.022171396762132645\n",
      "iteration 53 with loss 0.026050299406051636\n",
      "iteration 54 with loss 0.03255322948098183\n",
      "iteration 55 with loss 0.026948392391204834\n",
      "iteration 56 with loss 0.023532869294285774\n",
      "iteration 57 with loss 0.02279188483953476\n",
      "iteration 58 with loss 0.024768201634287834\n",
      "iteration 59 with loss 0.02384166046977043\n",
      "iteration 60 with loss 0.025534283369779587\n",
      "iteration 61 with loss 0.023878537118434906\n",
      "iteration 62 with loss 0.01744457334280014\n",
      "iteration 63 with loss 0.01068549882620573\n",
      "iteration 64 with loss 0.018854187801480293\n",
      "iteration 65 with loss 0.01397640723735094\n",
      "iteration 66 with loss 0.014322957023978233\n",
      "iteration 67 with loss 0.00784828420728445\n",
      "iteration 68 with loss 0.015125863254070282\n",
      "iteration 69 with loss 0.011706520803272724\n",
      "iteration 70 with loss 0.010356402024626732\n",
      "iteration 71 with loss 0.010507567785680294\n",
      "iteration 72 with loss 0.0085351737216115\n",
      "iteration 73 with loss 0.008149412460625172\n",
      "iteration 74 with loss 0.007394777145236731\n",
      "iteration 75 with loss 0.0041252137161791325\n",
      "iteration 76 with loss 0.007325059734284878\n",
      "iteration 77 with loss 0.004225192591547966\n",
      "iteration 78 with loss 0.00552705954760313\n",
      "iteration 79 with loss 0.005880812648683786\n",
      "iteration 80 with loss 0.006272132974117994\n",
      "iteration 81 with loss 0.003222860163077712\n",
      "iteration 82 with loss 0.005884816870093346\n",
      "iteration 83 with loss 0.0035097438376396894\n",
      "iteration 84 with loss 0.005251692607998848\n",
      "iteration 85 with loss 0.005707685835659504\n",
      "iteration 86 with loss 0.003127788659185171\n",
      "iteration 87 with loss 0.0027884359005838633\n",
      "iteration 88 with loss 0.004568313714116812\n",
      "iteration 89 with loss 0.0025422151666134596\n",
      "iteration 90 with loss 0.0016729753697291017\n",
      "iteration 91 with loss 0.0035289982333779335\n",
      "iteration 92 with loss 0.0016110112192109227\n",
      "iteration 93 with loss 0.0029011431615799665\n",
      "iteration 94 with loss 0.0015002115396782756\n",
      "iteration 95 with loss 0.0027219068724662066\n",
      "iteration 96 with loss 0.004007971379905939\n",
      "iteration 97 with loss 0.0012513422407209873\n",
      "iteration 98 with loss 0.00218919082544744\n",
      "iteration 99 with loss 0.002706077415496111\n",
      "iteration 100 with loss 0.002446003956720233\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(nr_iters):\n",
    "    x = torch.FloatTensor(batch_size).uniform_(*domain)\n",
    "    loss = loss_function(params, x)\n",
    "    params = optimizer.step(loss, params)\n",
    "    print(f'iteration {iteration + 1} with loss {float(loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3884aaa0-b27b-4773-97a3-499eb2f7b929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
